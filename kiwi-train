#!/usr/bin/python
import os, sys
import random
import itertools
import time
import argparse

from classify_kiwi import WINDOW_SIZE, BASENAME

from classify import Trainer, lr_steps, gst_init
from classify import add_common_args, process_common_args

def main():
    gst_init()
    parser = argparse.ArgumentParser()
    add_common_args(parser, WINDOW_SIZE=WINDOW_SIZE,
                    BASENAME=BASENAME)
    group = parser.add_argument_group('kiwi-train specific arguments')
    group.add_argument('-l', '--learn-rate', type=float,
                       help="learning rate")
    group.add_argument('-N', '--no-save-net', action='store_true',
                       help="don't save the net, periodically or otherwise")
    group.add_argument('-C', '--channels', default=12, type=int,
                       help="how many channels to use")
    group.add_argument('-r', '--random-alignment', action='store_true',
                       help="slightly randomise alignment of fft windows")
    group.add_argument('-E', '--error-weights',
                       help="multiply output errors by these ratios")
    group.add_argument('--bptt-depth', type=int,
                       help="Depth of BPTT training")
    group.add_argument('--activity-bias', type=int, default=1,
                       help="Train more on examples with changing classes")
    group.add_argument('-P', '--prioritise', type=int, default=False,
                       help="Do not renice downwards")

    args = parser.parse_args()
    if args.learn_rate:
        lr = lr_steps(args.learn_rate)
    else:
        lr = lr_steps(
            3e-5, 20,
            1e-5, 80,
            3e-6, 100,
            1e-6, 200,
            3e-7, 400,
            1e-7, 2000,
            3e-8)
    if 0:
        dropout = lr_steps(0.5, 100,
                           0.4, 100,
                           0.3, 100,
                           0.2, 100,
                           0.1, 100,
                           0
                       )
    else:
        dropout = 0

    if not args.prioritise and hasattr(os, 'nice'):
        os.nice(10)

    n_channels = args.channels

    c = Trainer(channels=n_channels)
    c.no_save_net = args.no_save_net
    c.setp('random-alignment', args.random_alignment)
    if args.bptt_depth:
        c.setp('bptt-depth', args.bptt_depth)
    timed_files, full_timings = process_common_args(c, args)

    validate_streams = [[ffn for fn, ffn in timed_files[:n_channels]]]
    training_streams = [[ffn for fn, ffn in timed_files[n_channels:]]]
    for i in range(args.activity_bias):
        stream = [ffn for fn, ffn in timed_files[n_channels:]
                  if len(full_timings[ffn]) > i + 1]
        if len(stream) > min(n_channels * 10, len(timed_files) / 4):
            training_streams.append(stream)
        else:
            training_streams.append(training_streams[-1][:])

    for x in training_streams:
        random.shuffle(x)

    if args.error_weights:
        c.setp('error-weight', args.error_weights)

    c.train(training_streams, validate_streams, full_timings,
            iterations=args.iterations,
            learn_rate=lr, dropout=dropout,
            properties=(('momentum-soft-start', 10000),
                        ('momentum', 0.93),
                        #('momentum-style', 1),
                        ('weight-fan-in-sum', 4),
                        ('weight-fan-in-kurtosis', 0.15),
                        #('weight-diagonal', 0.33),
                    ))

main()
