#!/usr/bin/python

import os, sys
import argparse
import json
import csv
import re
import random

from classify_stats import draw_roc_curve, calc_stats, draw_presence_roc
from classify_stats import actually_show_roc

def get_top_score_json_scores_and_names(fn, index):
    f = open(fn)
    results = {}
    for line in f:
        a = json.loads(line)
        n = os.path.basename(a[0]).encode('utf-8')
        n = n.replace('.wav-8k.wav', '.wav')
        results[n] = a[index + 1]
    return results



def get_call_json_presence_scores_and_names(fn):
    f = open(fn)
    results = {}
    for line in f:
        a = json.loads(line)
        score = 0
        for s, e, sc in a[1:]:
            if sc > score:
                score = sc
        n = os.path.basename(a[0]).encode('utf-8')
        n = n.replace('.wav-8k.wav', '.wav')
        results[n] = score
    return results

def get_csv_species_presence(fn, species_re):
    results = {}
    times = {}
    species = re.compile(species_re)
    with open(fn) as f:
        for record in csv.DictReader(f):
            wav = record['filename']
            if species.search(record['name']):
                t = times.setdefault(wav, [])
                t.append(record['offset'])
                results[wav] = True
            elif wav not in results:
                results[wav] = False
    return times, results

def print_times_strings(name, times, f=None):
    times = times.get(name, [])
    print "  ", name, ' '.join(times)
    if f:
        print >> f, name,
        for t in times:
            n = float(t)
            print >>f, "%.2f %.2f" % (n, n + 1.0),
        print >>f


def count_and_sample_classifications(args, truth, predictions, times, do_roc):
    tp, fp, tn, fn = [], [], [], []
    not_in_csv, not_in_pred = 0, 0
    for k in truth:
        not_in_pred += k not in predictions
        #if k not in predictions:
        #    print k
    for k, p in predictions.items():
        t = truth.get(k)
        predicted = p > args.threshold
        if t is None:
            not_in_csv += 1
            if predicted:
                fp.append(k)
            else:
                tn.append(k)
        elif not t:
            if predicted:
                fp.append(k)
            else:
                tn.append(k)
        else:
            if predicted:
                tp.append(k)
            else:
                fn.append(k)

    print "tp %d" % len(tp)
    print "fp %d" % len(fp)
    print "fn %d" % len(fn)
    print "tn %d" % len(tn)
    print "missing from truth %d" % not_in_csv
    print "missing from predictions %d" % not_in_pred

    if do_roc:
        if args.sample_file:
            sf = open(args.sample_file, 'w')
        else:
            sf = None

        print "sample being written to %s" % args.sample_file
        print "10 random false negatives:"
        random.shuffle(fn)
        for i, x in enumerate(fn):
            print_times_strings(x, times, f=sf)
            if i >= 9: break

        print "10 random false positives:"
        random.shuffle(fp)
        for i, x in enumerate(fp):
            print_times_strings(x, times, f=sf)
            if i >= 9: break
        if sf is not None:
            sf.close()

        if args.sample_file_script:
            f = open(args.sample_file_script, 'w')
            print >> f, "#!/bin/bash -x"
            print >> f, "#execute this and look at http:127.0.0.1:5000"
            print >> f, "dummy_dbm=$(mktemp -u --suffix=.dbm)"
            print >> f, 'cd "%s"' % os.path.expanduser(args.sample_file_server_dir)
            print >> f, ("./server.py -t '%s' --dbm-file=$dummy_dbm -s wideband "
                         "--include-wav-dir=doc-training-2011-12 "
                         "--include-wav-dir=doc-training-2012-13 "
                         "--timed-files-only "
                         % (args.sample_file, ))
            print >> f, "rm $dummy_dbm"
            f.close()
            os.chmod(args.sample_file_script, 0755)
            print "execute %s and look at http:127.0.0.1:5000" % args.sample_file_script

        #print truth


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--csv', action='append',
                        help="CSV of doc calls (possibly multiple)")
    parser.add_argument('--call-json',
                        help="JSON of classified calls")
    parser.add_argument('--json',
                        help="JSON of call top scores")
    parser.add_argument('--score-index', type=int,
                        help="Nth highest score to indicate presence")
    parser.add_argument('--species-regex',
                        help="species to look for in DOC csv")
    parser.add_argument('--threshold', type=float,
                        help="threshold for simple calculations")
    parser.add_argument('--just-the-numbers', action='store_true',
                        help="don't do ROC curves or samples")
    parser.add_argument('--mcc-threshold', type=float, default=None,
                        help="do roc curves if mcc > this")
    parser.add_argument('--auc-threshold', type=float, default=None,
                        help="do roc curves if auc > this")
    parser.add_argument('--sample-file', default='/tmp/doc-sample.txt',
                        help="write samples to this file")
    parser.add_argument('--sample-file-script', default='/tmp/doc-sample-server.sh',
                        help="executable script to view samples in web")
    parser.add_argument('--sample-file-server-dir', default='~/sonograms',
                        help="path to clone of "
                        "https://github.com/douglasbagnall/sonograms")

    args = parser.parse_args()
    if args.call_json:
        predictions = get_call_json_presence_scores_and_names(args.call_json)
    else:
        index = args.score_index
        predictions = get_top_score_json_scores_and_names(args.json, index)


    truth = {}
    times = {}
    for csvfn in args.csv:
        ftimes, ftruth = get_csv_species_presence(csvfn, args.species_regex)
        times.update(ftimes)
        truth.update(ftruth)


    data = []
    for k, v in predictions.iteritems():
        gt = truth.get(k, False)
        data.append((v, gt))

    stats = calc_stats(data, include_scores=True)
    print stats
    do_roc = not (args.just_the_numbers or
                  (args.mcc_threshold is not None and args.mcc_threshold < stats['mcc']) or
                  (args.auc_threshold is not None and args.auc_threshold < stats['auc']))

    if args.threshold == 0:
        args.threshold = stats['best_dfd_score']
        #args.threshold = stats['pos_95_score']

    if args.threshold:
        print args.threshold
        count_and_sample_classifications(args, truth, predictions, times, do_roc)
    else:
        print "no threshold?"

    if do_roc:
        draw_roc_curve(data, arrows=1)
        actually_show_roc()


main()
